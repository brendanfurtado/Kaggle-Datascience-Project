{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#initiating training data and seperating them into training set and test sets \n",
    "\n",
    "reddit_data = pd.read_csv(\"reddit_train.csv\") #train data\n",
    "df = pd.DataFrame(reddit_data) #train data\n",
    "reddit_data_copy = reddit_data.copy() #train data\n",
    "reddit_data_copy = reddit_data_copy.drop(columns=[\"subreddits\"]) #train data\n",
    "X = reddit_data_copy[reddit_data_copy.columns[1]]  #raw comments\n",
    "\n",
    "train_comments_list = []\n",
    "for i in range(len(X.index)):\n",
    "    train_comments_list.append(X.iloc[i])\n",
    "train_comments_list = list(train_comments_list)\n",
    "train_comments_list = np.array(train_comments_list)\n",
    "\n",
    "\n",
    "Y = reddit_data[reddit_data.columns[-1]]\n",
    "y_modified = []         #raw classes\n",
    "train_subreddits_class = []    #important, class in integer\n",
    "for i in range(len(Y.index)):\n",
    "    y_modified.append(Y.loc[i])\n",
    "for i in range(len(y_modified)):\n",
    "    if y_modified[i] == 'hockey':\n",
    "        train_subreddits_class.append(1)\n",
    "    elif y_modified[i] == 'nba':\n",
    "        train_subreddits_class.append(2)\n",
    "    elif y_modified[i] == 'leagueoflegends':\n",
    "        train_subreddits_class.append(3)\n",
    "    elif y_modified[i] == 'soccer':\n",
    "        train_subreddits_class.append(4)\n",
    "    elif y_modified[i] == 'funny':\n",
    "        train_subreddits_class.append(5)\n",
    "    elif y_modified[i] == 'movies':\n",
    "        train_subreddits_class.append(6)\n",
    "    elif y_modified[i] == 'Overwatch':\n",
    "        train_subreddits_class.append(7)\n",
    "    elif y_modified[i] == 'anime':\n",
    "        train_subreddits_class.append(8)\n",
    "    elif y_modified[i] == 'trees':\n",
    "        train_subreddits_class.append(9)\n",
    "    elif y_modified[i] == 'GlobalOffensive':\n",
    "        train_subreddits_class.append(10)\n",
    "    elif y_modified[i] == 'nfl':\n",
    "        train_subreddits_class.append(11)\n",
    "    elif y_modified[i] == 'AskReddit':\n",
    "        train_subreddits_class.append(12)\n",
    "    elif y_modified[i] == 'gameofthrones':\n",
    "        train_subreddits_class.append(13)\n",
    "    elif y_modified[i] == 'conspiracy':\n",
    "        train_subreddits_class.append(14)\n",
    "    elif y_modified[i] == 'worldnews':\n",
    "        train_subreddits_class.append(15)\n",
    "    elif y_modified[i] == 'wow':\n",
    "        train_subreddits_class.append(16)\n",
    "    elif y_modified[i] == 'europe':\n",
    "        train_subreddits_class.append(17)\n",
    "    elif y_modified[i] == 'canada':\n",
    "        train_subreddits_class.append(18)\n",
    "    elif y_modified[i] == 'Music':\n",
    "        train_subreddits_class.append(19)\n",
    "    elif y_modified[i] == 'baseball':\n",
    "        train_subreddits_class.append(20)\n",
    "train_subreddits_class = np.array(train_subreddits_class)\n",
    "X_train = train_comments_list\n",
    "y_train = train_subreddits_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/theone/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'\"] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.preprocessing import normalize\n",
    "import re\n",
    "\n",
    "#preprocess and normalize data by lammatizing, removing punctuation and stems etc. \n",
    "\n",
    "lem = WordNetLemmatizer()\n",
    "tknzr = WordPunctTokenizer()\n",
    "stem = PorterStemmer()\n",
    "replace_by_space = re.compile('[/(){}\\[\\]\\|@,;!.#><?\"\"''%$^*`:]')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "unused_char = re.compile('[^0-9a-zA-Z]')\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    X_train[i] = X_train[i].lower()\n",
    "    X_train[i] = replace_by_space.sub(' ', X_train[i])\n",
    "    X_train[i] = unused_char.sub(' ', X_train[i])\n",
    "    X_train[i] = ' '.join(lem.lemmatize(word) for word in X_train[i].split() if word not in stop_words)\n",
    "\n",
    "tf_idf_vectorizer = TfidfVectorizer(stop_words = set(stopwords.words('english')), max_df = 1.0, ngram_range=(1, 3), min_df = 0.000005, analyzer='word',binary=True, tokenizer = WordPunctTokenizer().tokenize)\n",
    "vectors_train_idf = tf_idf_vectorizer.fit_transform(X_train)\n",
    "terms = tf_idf_vectorizer.get_feature_names()\n",
    "vectors_train_nomalized = normalize(vectors_train_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature selection\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, f_regression, mutual_info_classif\n",
    "skb = SelectKBest(chi2, k=70000)\n",
    "vectors_train_idf_normalized_selected = skb.fit_transform(vectors_train_nomalized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectors_train_idf_normalized_selected, y_train, train_size=0.9, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.67      0.69       348\n",
      "           2       0.72      0.70      0.71       351\n",
      "           3       0.75      0.75      0.75       336\n",
      "           4       0.72      0.65      0.68       327\n",
      "           5       0.33      0.36      0.34       346\n",
      "           6       0.58      0.67      0.62       357\n",
      "           7       0.80      0.73      0.77       337\n",
      "           8       0.73      0.73      0.73       367\n",
      "           9       0.56      0.59      0.58       367\n",
      "          10       0.86      0.67      0.75       374\n",
      "          11       0.70      0.69      0.69       360\n",
      "          12       0.30      0.38      0.34       336\n",
      "          13       0.93      0.68      0.78       354\n",
      "          14       0.40      0.50      0.45       334\n",
      "          15       0.46      0.37      0.41       366\n",
      "          16       0.73      0.77      0.75       366\n",
      "          17       0.55      0.62      0.58       331\n",
      "          18       0.46      0.64      0.53       360\n",
      "          19       0.85      0.59      0.70       328\n",
      "          20       0.75      0.70      0.72       355\n",
      "\n",
      "    accuracy                           0.62      7000\n",
      "   macro avg       0.64      0.62      0.63      7000\n",
      "weighted avg       0.65      0.62      0.63      7000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Multinomial Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf_nb = MultinomialNB(alpha=0.001)\n",
    "clf_nb.fit(X_train, y_train)\n",
    "y_pred = clf_nb.predict(X_test)\n",
    "\n",
    "#printing the predictions\n",
    "#print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.62      0.66       326\n",
      "           2       0.81      0.68      0.74       370\n",
      "           3       0.72      0.74      0.73       333\n",
      "           4       0.61      0.66      0.63       340\n",
      "           5       0.28      0.28      0.28       353\n",
      "           6       0.59      0.61      0.60       352\n",
      "           7       0.84      0.72      0.77       331\n",
      "           8       0.66      0.70      0.68       374\n",
      "           9       0.58      0.63      0.60       361\n",
      "          10       0.69      0.60      0.64       345\n",
      "          11       0.58      0.65      0.61       335\n",
      "          12       0.28      0.30      0.29       343\n",
      "          13       0.88      0.69      0.77       342\n",
      "          14       0.51      0.54      0.53       366\n",
      "          15       0.46      0.26      0.34       356\n",
      "          16       0.77      0.73      0.75       362\n",
      "          17       0.40      0.67      0.50       353\n",
      "          18       0.46      0.52      0.49       328\n",
      "          19       0.72      0.62      0.67       392\n",
      "          20       0.65      0.69      0.67       338\n",
      "\n",
      "    accuracy                           0.60      7000\n",
      "   macro avg       0.61      0.60      0.60      7000\n",
      "weighted avg       0.61      0.60      0.60      7000\n",
      "\n",
      "7000\n"
     ]
    }
   ],
   "source": [
    "#linear model\n",
    "from sklearn import linear_model\n",
    "class_weights = {1: 0.9, 2:0.7, 3:0.7, 4:0.9, 5:1.5, 6:0.9, 7:0.5, 8:0.9, 9:1, 10:0.8, 11:0.9, 12:1.5, 13:0.3, 14:1.2, 15:1.2, 16:0.5, 17:1.2, 18:1.2, 19:0.5, 20:0.9}\n",
    "\n",
    "clf_SDG = linear_model.SGDClassifier(max_iter=1000, tol=1e-3, class_weight=class_weights, penalty='l2', alpha=0.0001, random_state=0)\n",
    "clf_SDG.fit(X_train, y_train)\n",
    "y_pred = clf_SDG.predict(X_test)\n",
    "\n",
    "#printing the predictions\n",
    "#print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.62      0.65       326\n",
      "           2       0.84      0.65      0.73       370\n",
      "           3       0.73      0.72      0.73       333\n",
      "           4       0.70      0.64      0.67       340\n",
      "           5       0.22      0.36      0.27       353\n",
      "           6       0.63      0.57      0.60       352\n",
      "           7       0.84      0.70      0.77       331\n",
      "           8       0.65      0.66      0.66       374\n",
      "           9       0.61      0.62      0.61       361\n",
      "          10       0.69      0.65      0.67       345\n",
      "          11       0.68      0.62      0.65       335\n",
      "          12       0.22      0.43      0.29       343\n",
      "          13       0.98      0.53      0.69       342\n",
      "          14       0.46      0.51      0.48       366\n",
      "          15       0.36      0.39      0.37       356\n",
      "          16       0.96      0.44      0.61       362\n",
      "          17       0.53      0.60      0.56       353\n",
      "          18       0.46      0.51      0.48       328\n",
      "          19       0.78      0.61      0.68       392\n",
      "          20       0.71      0.70      0.70       338\n",
      "\n",
      "    accuracy                           0.58      7000\n",
      "   macro avg       0.64      0.58      0.59      7000\n",
      "weighted avg       0.64      0.58      0.59      7000\n",
      "\n",
      "7000\n"
     ]
    }
   ],
   "source": [
    "#Linear SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "class_weights = {1: 0.9, 2:0.7, 3:0.7, 4:0.9, 5:1.5, 6:0.9, 7:0.5, 8:0.9, 9:1, 10:0.8, 11:0.9, 12:1.5, 13:0.1, 14:1.2, 15:1.2, 16:0.1, 17:1.2, 18:1.2, 19:0.5, 20:0.9}\n",
    "clf_svc = LinearSVC(random_state=0, tol=1e-5, class_weight=class_weights)\n",
    "clf_svc.fit(X_train, y_train)\n",
    "y_pred = clf_svc.predict(X_test)\n",
    "\n",
    "#printing the predictions\n",
    "#print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yoooooooh/Desktop/Anaconda3/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:568: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.65      0.70       326\n",
      "           2       0.77      0.72      0.75       370\n",
      "           3       0.74      0.74      0.74       333\n",
      "           4       0.77      0.65      0.70       340\n",
      "           5       0.24      0.30      0.27       353\n",
      "           6       0.62      0.62      0.62       352\n",
      "           7       0.76      0.76      0.76       331\n",
      "           8       0.70      0.69      0.70       374\n",
      "           9       0.64      0.62      0.63       361\n",
      "          10       0.77      0.62      0.69       345\n",
      "          11       0.63      0.67      0.65       335\n",
      "          12       0.29      0.40      0.34       343\n",
      "          13       0.85      0.75      0.80       342\n",
      "          14       0.50      0.50      0.50       366\n",
      "          15       0.37      0.49      0.42       356\n",
      "          16       0.75      0.79      0.77       362\n",
      "          17       0.60      0.57      0.59       353\n",
      "          18       0.61      0.46      0.53       328\n",
      "          19       0.77      0.68      0.72       392\n",
      "          20       0.69      0.71      0.70       338\n",
      "\n",
      "    accuracy                           0.62      7000\n",
      "   macro avg       0.64      0.62      0.63      7000\n",
      "weighted avg       0.64      0.62      0.63      7000\n",
      "\n",
      "7000\n"
     ]
    }
   ],
   "source": [
    "#MLP\n",
    "#need to manually terminate this cell after 3/4 minutes\n",
    "#if an error appears, wait longer \n",
    "from sklearn import metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf_mlp = MLPClassifier(alpha = 0.00001, learning_rate = 'adaptive', learning_rate_init = 0.005, early_stopping = True, max_iter = 100, activation = 'relu', random_state=0)\n",
    "clf_mlp.fit(X_train, y_train)\n",
    "y_pred = clf_mlp.predict(X_test)\n",
    "\n",
    "#printing the predictions\n",
    "#print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nfl' 'europe' 'anime' ... 'GlobalOffensive' 'gameofthrones' 'wow']\n",
      "30000\n"
     ]
    }
   ],
   "source": [
    "#initializing test data set\n",
    "reddit_data_test = pd.read_csv[\"reddit_test.csv\"]\n",
    "df = pd.DataFrame(reddit_data_test)\n",
    "X = reddit_data_test[reddit_data_test.columns[1]]\n",
    "train_comments_list = []\n",
    "for i in range(len(X.index)):\n",
    "    train_comments_list.append(X.iloc[i])\n",
    "train_comments_list = np.array(train_comments_list)\n",
    "\n",
    "for i in range(len(train_comments_list)):\n",
    "    train_comments_list[i] = train_comments_list[i].lower()\n",
    "    train_comments_list[i] = replace_by_space.sub(' ', train_comments_list[i])\n",
    "    train_comments_list[i] = unused_char.sub(' ', train_comments_list[i])\n",
    "    train_comments_list[i] = ' '.join(lem.lemmatize(word) for word in train_comments_list[i].split() if word not in stop_words)\n",
    "\n",
    "vectors_real_test_idf = tf_idf_vectorizer.transform(train_comments_list)\n",
    "vectors_real_test_idf_selected_nomalized = normalize(vectors_real_test_idf)\n",
    "vectors_real_test_idf_selected = skb.transform(vectors_real_test_idf_selected_nomalized)\n",
    "\n",
    "y_pred1 = clf_nb.predict(vectors_real_test_idf_selected)\n",
    "y_pred2 = clf_svc.predict(vectors_real_test_idf_selected)\n",
    "y_pred3 = clf_mlp.predict(vectors_real_test_idf_selected)\n",
    "y_pred4 = clf_SDG.predict(vectors_real_test_idf_selected)\n",
    "\n",
    "#outputs the final prediction using hard voting classifier: seeing which prediction of the class is most agreed among the different models \n",
    "y_pred = []\n",
    "for i in range(len(y_pred1)):\n",
    "    if y_pred1[i] == y_pred2[i] == y_pred3[i] == y_pred4[i]:\n",
    "        y_pred.append(y_pred1[i])\n",
    "        \n",
    "    elif y_pred1[i] == y_pred2[i] == y_pred3[i] != y_pred4[i]:\n",
    "        y_pred.append(y_pred1[i])\n",
    "        \n",
    "    elif y_pred1[i] == y_pred3[i] == y_pred4[i] != y_pred2[i]:\n",
    "        y_pred.append(y_pred1[i])\n",
    "        \n",
    "    elif y_pred1[i] == y_pred2[i] == y_pred4[i] != y_pred3[i]:\n",
    "        y_pred.append(y_pred1[i])\n",
    "        \n",
    "    elif y_pred1[i] != y_pred2[i] == y_pred3[i] == y_pred4[i]:\n",
    "        y_pred.append(y_pred4[i])\n",
    "        \n",
    "    elif y_pred1[i] == y_pred2[i] != y_pred3[i] == y_pred4[i]:\n",
    "        y_pred.append(y_pred1[i])\n",
    "        \n",
    "    elif y_pred1[i] == y_pred3[i] != y_pred2[i] == y_pred4[i]:\n",
    "        y_pred.append(y_pred1[i])   \n",
    "        \n",
    "    elif y_pred1[i] == y_pred4[i] != y_pred2[i] == y_pred3[i]:\n",
    "        y_pred.append(y_pred1[i])\n",
    "        \n",
    "    elif y_pred1[i] == y_pred2[i] != y_pred3[i] != y_pred4[i]:\n",
    "        y_pred.append(y_pred1[i])\n",
    "        \n",
    "    elif y_pred1[i] == y_pred3[i] != y_pred4[i] != y_pred2[i]:\n",
    "        y_pred.append(y_pred1[i])\n",
    "        \n",
    "    elif y_pred1[i] == y_pred4[i] != y_pred2[i] != y_pred3[i]:\n",
    "        y_pred.append(y_pred1[i])\n",
    "        \n",
    "    elif y_pred2[i] == y_pred3[i] != y_pred1[i] != y_pred4[i]:\n",
    "        y_pred.append(y_pred2[i])    \n",
    "        \n",
    "    elif y_pred2[i] == y_pred4[i] != y_pred1[i] != y_pred3[i]:\n",
    "        y_pred.append(y_pred2[i]) \n",
    "        \n",
    "    elif y_pred3[i] == y_pred4[i] != y_pred1[i] != y_pred2[i]:\n",
    "        y_pred.append(y_pred3[i])\n",
    "    \n",
    "    elif y_pred3[i] != y_pred4[i] != y_pred1[i] != y_pred2[i]:\n",
    "        y_pred.append(y_pred1[i])\n",
    "        \n",
    "        \n",
    "        \n",
    "#change classes back to string format\n",
    "y_pred_modified = []\n",
    "for i in range(len(y_pred)):        #raw classes\n",
    "    if y_pred[i] == 1:\n",
    "        y_pred_modified.append('hockey')\n",
    "    elif y_pred[i] == 2:\n",
    "        y_pred_modified.append('nba')\n",
    "    elif y_pred[i] == 3:\n",
    "        y_pred_modified.append('leagueoflegends')\n",
    "    elif y_pred[i] == 4:\n",
    "        y_pred_modified.append('soccer')\n",
    "    elif y_pred[i] == 5:\n",
    "        y_pred_modified.append('funny')\n",
    "    elif y_pred[i] == 6:\n",
    "        y_pred_modified.append('movies')\n",
    "    elif y_pred[i] == 7:\n",
    "        y_pred_modified.append('Overwatch')\n",
    "    elif y_pred[i] == 8:\n",
    "        y_pred_modified.append('anime')\n",
    "    elif y_pred[i] == 9:\n",
    "        y_pred_modified.append('trees')\n",
    "    elif y_pred[i] == 10:\n",
    "        y_pred_modified.append('GlobalOffensive')\n",
    "    elif y_pred[i] == 11:\n",
    "        y_pred_modified.append('nfl')\n",
    "    elif y_pred[i] == 12:\n",
    "        y_pred_modified.append('AskReddit')\n",
    "    elif y_pred[i] == 13:\n",
    "        y_pred_modified.append('gameofthrones')\n",
    "    elif y_pred[i] == 14:\n",
    "        y_pred_modified.append('conspiracy')\n",
    "    elif y_pred[i] == 15:\n",
    "        y_pred_modified.append('worldnews')\n",
    "    elif y_pred[i] == 16:\n",
    "        y_pred_modified.append('wow')\n",
    "    elif y_pred[i] == 17:\n",
    "        y_pred_modified.append('europe')\n",
    "    elif y_pred[i] == 18:\n",
    "        y_pred_modified.append('canada')\n",
    "    elif y_pred[i] == 19:\n",
    "        y_pred_modified.append('Music')\n",
    "    elif y_pred[i] == 20:\n",
    "        y_pred_modified.append('baseball')\n",
    "y_pred_modified = np.array(y_pred_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred_modified' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-25bc43be5fad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#output the prediction results as a csv file. Please rename the file manually if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prediction_voted4.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_modified\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred_modified\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"%s,%s\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Id,Category\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred_modified' is not defined"
     ]
    }
   ],
   "source": [
    "#output the prediction results as a csv file. Please rename the file manually if needed\n",
    "np.savetxt(\"prediction_voted4.csv\", np.dstack((np.arange(0, y_pred_modified.size),y_pred_modified))[0],\"%s,%s\",header=\"Id,Category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
